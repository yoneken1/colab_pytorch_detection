{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoneken1/colab_pytorch_detection/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PmilvHo_kSTv",
        "colab_type": "code",
        "outputId": "67b4fc75-76a6-4874-bc60-6362299de00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import vgg16,squeezenet1_1\n",
        "from anchor import Anchor\n",
        "\n",
        "class GLDet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes):\n",
        "    super(GLDet, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    base_model = squeezenet1_1(pretrained=True)\n",
        "    self.features = base_model.features\n",
        "    self.anchor_gen = Anchor(scale_ratios = [1/2., 1., 1.5])\n",
        "   \n",
        "    \n",
        "    for p in self.features[0].parameters():\n",
        "          p.requires_grad = False \n",
        "    for p in self.features[3].parameters():\n",
        "          p.requires_grad = False \n",
        "        \n",
        "    num_anchors = self.anchor_gen.num_anchors\n",
        "        \n",
        "    self.conv1 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.loc = nn.Conv2d(512, num_anchors * 4 * num_classes, 1, 1, 0)\n",
        "    self.cls = nn.Conv2d(512, num_anchors * (num_classes+1), 1, 1, 0)\n",
        "    \n",
        "    nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
        "    self.conv1.bias.data.zero_()\n",
        "    self.loc.weight.data.normal_(0.0, 0.001)\n",
        "    self.loc.bias.data.zero_()\n",
        "    self.cls.weight.data.normal_(0.0, 0.01)\n",
        "    self.cls.bias.data.zero_()\n",
        "    \n",
        "    \n",
        "  def forward(self,x):\n",
        "    fm = self.features(x)\n",
        "    h = self.relu1(self.conv1(fm))\n",
        "    pred_loc = self.loc(h)\n",
        "    pred_cls = self.cls(h)\n",
        "    pred_loc = pred_loc.permute(0, 2, 3, 1).contiguous().view(pred_loc.size(0), -1, 4 * self.num_classes)\n",
        "    pred_cls = pred_cls.permute(0, 2, 3, 1).contiguous().view(pred_cls.size(0), -1, self.num_classes+1)\n",
        "    \n",
        "    fm_size = fm.size()\n",
        "    anchor = self.anchor_gen.get_anchor_boxes([fm_size])\n",
        "    \n",
        "    return pred_loc,pred_cls,anchor\n",
        "    \n",
        "#device = torch.device('cuda')\n",
        "device = torch.device('cpu')\n",
        "    \n",
        "def test():\n",
        "  x = torch.randn((1,3,600,600))\n",
        "  model = GLDet(6)\n",
        "  x = x.to(device)\n",
        "  model = model.to(device)\n",
        "  pred_loc,pred_cls,anchor = model(x)\n",
        "  \n",
        "test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "  init.kaiming_uniform(m.weight.data)\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "85n78UtEtV_E",
        "colab_type": "code",
        "outputId": "ca54a027-007e-4e58-bd87-0cf9a14600b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pretrainedmodels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.2.1)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (2.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (5.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hciRmeQitzpx",
        "colab_type": "code",
        "outputId": "1624ad67-f370-47f6-f33e-77b1e16968bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5326
        }
      },
      "cell_type": "code",
      "source": [
        "import pretrainedmodels\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "model_name = 'se_resnext50_32x4d' \n",
        "\n",
        "base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "features = nn.Sequential(base_model.layer0, base_model.layer1,base_model.layer2, base_model.layer3, base_model.layer4)\n",
        "\n",
        "print(base_model)\n",
        "\n",
        "for p in features[0].parameters():\n",
        "  p.requires_grad = False\n",
        "  \n",
        "for p in features[1].parameters():\n",
        "  p.requires_grad = False\n",
        "  \n",
        "\n",
        "#base_model = squeezenet1_1(pretrained=True)\n",
        "#features = base_model.features\n",
        "#for p in features[0].parameters():\n",
        "#  p.requires_grad = False \n",
        "#for p in features[3].parameters():\n",
        "#  p.requires_grad = False \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.torch/models/se_resnext50_32x4d-a260b3a4.pth\n",
            "100%|██████████| 110559176/110559176 [00:06<00:00, 16722246.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SENet(\n",
            "  (layer0): Sequential(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace)\n",
            "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (layer1): Sequential(\n",
            "    (0): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (2): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (2): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (3): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (2): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (3): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (4): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (5): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "    (2): SEResNeXtBottleneck(\n",
            "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (se_module): SEModule(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace)\n",
            "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (sigmoid): Sigmoid()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "  (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MalIAj3TlZvy",
        "colab_type": "code",
        "outputId": "e24f0153-f2df-4e3d-fedf-e084b43a2b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import vgg16,squeezenet1_1\n",
        "from anchor import Anchor\n",
        "\n",
        "class GCDet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes, model='senet'):\n",
        "    super(GCDet, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.model = model\n",
        "    \n",
        "    if model == 'senet':\n",
        "      model_name = 'se_resnext50_32x4d' \n",
        "      base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "      self.features = nn.Sequential(base_model.layer0, base_model.layer1,base_model.layer2, base_model.layer3)\n",
        "\n",
        "      for p in self.features[0].parameters():\n",
        "        p.requires_grad = False\n",
        "  \n",
        "      for p in self.features[1].parameters():\n",
        "        p.requires_grad = False\n",
        "      in_plane = 1024\n",
        "      h_plane = 256\n",
        "\n",
        "\n",
        "    else:\n",
        "      base_model = squeezenet1_1(pretrained=True)\n",
        "      self.features = base_model.features\n",
        "      for p in self.features[0].parameters():\n",
        "        p.require_grad = False \n",
        "      for p in self.features[3].parameters():\n",
        "            p.require_grad = False \n",
        "      in_plane = 512\n",
        "      h_plane = 256\n",
        "\n",
        "\n",
        "    self.anchor_gen = Anchor()\n",
        "        \n",
        "    num_anchors = self.anchor_gen.num_anchors\n",
        "        \n",
        "    #self.conv1 = nn.Conv2d(in_plane, h_plane, 3, 1, 1)\n",
        "    #self.relu1 = nn.ReLU(True)\n",
        "    #head_layer = []\n",
        "    #for _ in range(2):\n",
        "    #  head_layer.append(nn.Conv2d(h_plane, h_plane, 3, 1, 1))\n",
        "    #  head_layer.append(nn.ReLU(True))\n",
        "    #self.head = nn.Sequential(*head_layer)\n",
        "    #self.loc = nn.Conv2d(h_plane, num_anchors * 4 * num_classes, 3, 1, 1)\n",
        "    #self.cls = nn.Conv2d(h_plane, num_anchors * (num_classes+1), 3, 1, 1)\n",
        "    \n",
        "    self.loc_head = self._make_head_layer(in_plane, h_plane, 3)\n",
        "    self.cls_head = self._make_head_layer(in_plane, h_plane, 3)\n",
        "    self.loc = nn.Conv2d(h_plane, num_anchors * 4 * num_classes, 3, 1, 1)\n",
        "    self.cls = nn.Conv2d(h_plane, num_anchors * (num_classes+1), 3, 1, 1)\n",
        "    \n",
        "    #nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
        "    #self.conv1.bias.data.zero_()\n",
        "    for m in self.loc_head.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "    for m in self.cls_head.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "    \n",
        "    self.loc.weight.data.normal_(0.0, 0.001)\n",
        "    self.loc.bias.data.zero_()\n",
        "    self.cls.weight.data.normal_(0.0, 0.01)\n",
        "    self.cls.bias.data.zero_()\n",
        "    \n",
        "  def _make_head_layer(self, in_plane, h_plane, num_itr):\n",
        "    head_layer = []\n",
        "    head_layer.append(nn.Conv2d(in_plane, h_plane, 3, 1, 1))\n",
        "    head_layer.append(nn.ReLU(True))\n",
        "    for _ in range(num_itr):\n",
        "      head_layer.append(nn.Conv2d(h_plane, h_plane, 3, 1, 1))\n",
        "      head_layer.append(nn.ReLU(True))\n",
        "    \n",
        "    return nn.Sequential(*head_layer)\n",
        "    \n",
        "  def train(self, mode=True):\n",
        "    super(GCDet, self).train(mode)\n",
        "    #freeze bn\n",
        "    if self.model == 'senet':\n",
        "      if mode:\n",
        "        for layer in self.modules():\n",
        "          if isinstance(layer, nn.BatchNorm2d):\n",
        "            layer.eval()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    fm = self.features(x)\n",
        "    loc_h = self.loc_head(fm)\n",
        "    cls_h = self.cls_head(fm) \n",
        "    pred_loc = self.loc(loc_h)\n",
        "    pred_cls = self.cls(cls_h)\n",
        "    pred_loc = pred_loc.permute(0, 2, 3, 1).contiguous().view(pred_loc.size(0), -1, 4 * self.num_classes)\n",
        "    pred_cls = pred_cls.permute(0, 2, 3, 1).contiguous().view(pred_cls.size(0), -1, self.num_classes+1)\n",
        "    \n",
        "    fm_size = fm.size()\n",
        "    anchor = self.anchor_gen.get_anchor_boxes([fm_size])\n",
        "    \n",
        "    return pred_loc,pred_cls,anchor\n",
        "    \n",
        "device = torch.device('cuda')\n",
        "\n",
        "def testgc():\n",
        "  x = torch.randn((1,3,600,900))\n",
        "  model = GCDet(6)\n",
        "  x = x.to(device)\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  pred_loc,pred_cls,anchor = model(x)\n",
        "  print(pred_loc.size())\n",
        "  print(pred_cls.size())\n",
        "  print(anchor.size())\n",
        "  print(anchor[0])\n",
        "  print(anchor[9])\n",
        "  print(anchor[18])\n",
        "  print(anchor[57*9])\n",
        "  print(anchor[57*9+9])\n",
        "  print(anchor[57*9-9])\n",
        "  \n",
        "testgc()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 19494, 24])\n",
            "torch.Size([1, 19494, 7])\n",
            "torch.Size([19494, 4])\n",
            "tensor([-56., -56.,  71.,  71.])\n",
            "tensor([-40., -56.,  87.,  71.])\n",
            "tensor([-24., -56., 103.,  71.])\n",
            "tensor([-56., -40.,  71.,  87.])\n",
            "tensor([-40., -40.,  87.,  87.])\n",
            "tensor([840., -56., 967.,  71.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5nvWM0-Yt7wk",
        "colab_type": "code",
        "outputId": "d9188bb1-4f4f-4322-c5a1-0ba0c14f28f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import vgg16,squeezenet1_1,resnet34\n",
        "from anchor import Anchor\n",
        "\n",
        "\n",
        "class GCDet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes, model='resnet', class_agnostic=False):\n",
        "    super(GCDet, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.model = model\n",
        "    self.class_agnostic=class_agnostic\n",
        "    \n",
        "    if model == 'resnet':\n",
        "      model_name = 'resnet50' \n",
        "      \n",
        "      base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "      self.layer1 = nn.Sequential(base_model.conv1,base_model.bn1,base_model.relu,base_model.maxpool, base_model.layer1)\n",
        "      self.layer2 = base_model.layer2\n",
        "      self.layer3 = base_model.layer3\n",
        "      self.layer4 = base_model.layer4\n",
        "      self.latlayer4 = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.latlayer3 = nn.Conv2d(1024, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.toplayer3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "      self.latlayer2 = nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.toplayer2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "      self.conv5 = nn.Conv2d(2048, 256, kernel_size=3, stride=2, padding=1)\n",
        "      \n",
        "      #32 64 128 256\n",
        "      \n",
        "      for p in self.layer1.parameters():\n",
        "        p.requires_grad = False\n",
        "  \n",
        "      for p in self.layer2.parameters():\n",
        "        p.requires_grad = False\n",
        "        \n",
        "      for p in self.layer3.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    anchor_areas = [ 64*64., 128*128., 256*256., 512*512.] \n",
        "    aspect_ratios = [1/1.,1/2., 2/1.]\n",
        "    scale_ratios = [1., 1./pow(2.,1/3.), 1./pow(2.,2/3.)]\n",
        "    anchor_base_sizes = [8., 16., 32., 64. ]\n",
        "    self.anchor_gen = Anchor(anchor_areas=anchor_areas,\n",
        "                            aspect_ratios= aspect_ratios,\n",
        "                            scale_ratios = scale_ratios,\n",
        "                            anchor_base_sizes = anchor_base_sizes)\n",
        "        \n",
        "    num_anchors = self.anchor_gen.num_anchors\n",
        "        \n",
        "    self.loc_head = self._make_head_layer(256, 256, 2)\n",
        "    self.cls_head = self._make_head_layer(256, 256, 2)\n",
        "    if self.class_agnostic:\n",
        "      self.loc = nn.Conv2d(256, num_anchors * 4, 3, 1, 1)\n",
        "    else:\n",
        "      self.loc = nn.Conv2d(256, num_anchors * 4 * num_classes, 3, 1, 1)\n",
        "    self.cls = nn.Conv2d(256, num_anchors * (num_classes+1), 3, 1, 1)\n",
        "    \n",
        "    self._normal_init(self.loc_head)\n",
        "    self._normal_init(self.cls_head)\n",
        "    self._normal_init(self.latlayer4)\n",
        "    self._normal_init(self.latlayer3)\n",
        "    self._normal_init(self.toplayer3)\n",
        "    self._normal_init(self.latlayer2)\n",
        "    self._normal_init(self.toplayer2)\n",
        "    self._normal_init(self.conv5)\n",
        "   \n",
        "    \n",
        "    self.loc.weight.data.normal_(0.0, 0.001)\n",
        "    self.loc.bias.data.zero_()\n",
        "    self.cls.weight.data.normal_(0.0, 0.01)\n",
        "    self.cls.bias.data.zero_()\n",
        "    \n",
        "  def _make_head_layer(self, in_plane, h_plane, num_itr):\n",
        "    head_layer = []\n",
        "    head_layer.append(nn.Conv2d(in_plane, h_plane, 3, 1, 1))\n",
        "    head_layer.append(nn.ReLU(True))\n",
        "    for _ in range(num_itr):\n",
        "      head_layer.append(nn.Conv2d(h_plane, h_plane, 3, 1, 1))\n",
        "      head_layer.append(nn.ReLU(True))\n",
        "    \n",
        "    return nn.Sequential(*head_layer)\n",
        "  \n",
        "  def _normal_init(self, layer):\n",
        "    for m in layer.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "    \n",
        "  def train(self, mode=True):\n",
        "    super(GCDet, self).train(mode)\n",
        "    #freeze bn\n",
        "    if self.model == 'resnet':\n",
        "      if mode:\n",
        "        for layer in self.modules():\n",
        "          if isinstance(layer, nn.BatchNorm2d):\n",
        "            layer.eval()\n",
        "            \n",
        "  def _upsample_add(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    return nn.functional.upsample(x, size=(H,W), mode='bilinear') + y\n",
        "    \n",
        "  def forward(self,x):\n",
        "    c1 = self.layer1(x)\n",
        "    c2 = self.layer2(c1) #8\n",
        "    c3 = self.layer3(c2) #16\n",
        "    c4 = self.layer4(c3) #32\n",
        "    \n",
        "    p5 = self.conv5(c4) #64\n",
        "    p4 = self.latlayer4(c4)\n",
        "    p3 = self._upsample_add(p4, self.latlayer3(c3))\n",
        "    p3 = self.toplayer3(p3)\n",
        "    p2 = self._upsample_add(p3, self.latlayer2(c2))\n",
        "    p2 = self.toplayer2(p2)\n",
        "    \n",
        "    pred_locs = []\n",
        "    pred_clss = []\n",
        "    fm_size = []\n",
        "    for fm in [p2,p3,p4,p5]:\n",
        "      loc_h = self.loc_head(fm)\n",
        "      cls_h = self.cls_head(fm) \n",
        "      pred_loc = self.loc(loc_h)\n",
        "      pred_cls = self.cls(cls_h)\n",
        "      if self.class_agnostic:\n",
        "        pred_loc = pred_loc.permute(0, 2, 3, 1).contiguous().view(pred_loc.size(0), -1, 4)\n",
        "      else:\n",
        "        pred_loc = pred_loc.permute(0, 2, 3, 1).contiguous().view(pred_loc.size(0), -1, 4 * self.num_classes)\n",
        "      pred_cls = pred_cls.permute(0, 2, 3, 1).contiguous().view(pred_cls.size(0), -1, self.num_classes+1)\n",
        "    \n",
        "      pred_locs.append(pred_loc)\n",
        "      pred_clss.append(pred_cls)\n",
        "      fm_size.append(fm.size())\n",
        "    pred_locs = torch.cat(pred_locs,1)\n",
        "    pred_clss = torch.cat(pred_clss,1)\n",
        "    anchor = self.anchor_gen.get_anchor_boxes(fm_size)\n",
        "    \n",
        "    return pred_locs, pred_clss,anchor\n",
        "    \n",
        "#device = torch.device('cuda')\n",
        "\n",
        "def testgc():\n",
        "  x = torch.randn((1,3,600,900))\n",
        "  model = GCDet(6)\n",
        "  x = x.to(device)\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  pred_loc,pred_cls,anchor = model(x)\n",
        "  print(pred_loc[0].size())\n",
        "  print(pred_cls[0].size())\n",
        "  print(anchor.size())\n",
        "  print(anchor[0])\n",
        "  print(anchor[9])\n",
        "  print(anchor[18])\n",
        "  print(anchor[57*9])\n",
        "  print(anchor[57*9+9])\n",
        "  print(anchor[57*9-9])\n",
        "  \n",
        "testgc()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1024, 38, 57])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([68052, 24])\n",
            "torch.Size([68052, 7])\n",
            "torch.Size([68052, 4])\n",
            "tensor([-14., -14.,  17.,  17.])\n",
            "tensor([-10., -30.,  21.,  33.])\n",
            "tensor([ -2., -14.,  29.,  17.])\n",
            "tensor([326., -30., 357.,  33.])\n",
            "tensor([334., -14., 365.,  17.])\n",
            "tensor([322., -14., 353.,  17.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hiQPEloErqXv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Anchorを修正（ｔ１７）\n",
        "\n",
        "headをlとsに分ける\n"
      ]
    },
    {
      "metadata": {
        "id": "LG4S7LMLFQA1",
        "colab_type": "code",
        "outputId": "c8b0607e-45e7-4d4e-e727-e1bfdddea407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import vgg16,squeezenet1_1,resnet34\n",
        "from anchor import Anchor\n",
        "import pretrainedmodels\n",
        "device = torch.device('cpu')\n",
        "\n",
        "class GCDet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes, model='resnet', class_agnostic=False):\n",
        "    super(GCDet, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.model = model\n",
        "    self.class_agnostic=class_agnostic\n",
        "    \n",
        "    if model == 'resnet':\n",
        "      model_name = 'resnet50' \n",
        "      \n",
        "      base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "      self.layer1 = nn.Sequential(base_model.conv1,base_model.bn1,base_model.relu,base_model.maxpool, base_model.layer1)\n",
        "      self.layer2 = base_model.layer2\n",
        "      self.layer3 = base_model.layer3\n",
        "      self.layer4 = base_model.layer4\n",
        "      self.latlayer4 = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.latlayer3 = nn.Conv2d(1024, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.toplayer3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "      self.latlayer2 = nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.toplayer2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "      self.conv5 = nn.Conv2d(2048, 256, kernel_size=3, stride=2, padding=1)\n",
        "      self.avg_pool_1x1 = nn.AdaptiveAvgPool2d((1,1))\n",
        "      self.avg_pool_3x3 = nn.AdaptiveAvgPool2d((3,3))\n",
        "      self.avg_pool_5x5 = nn.AdaptiveAvgPool2d((5,5))\n",
        "      self.rconv1 = nn.Conv2d(2048, 64, kernel_size=1, stride=1, padding=0)\n",
        "      self.rconv3 = nn.Conv2d(2048, 64, kernel_size=1, stride=1, padding=0)\n",
        "      self.rconv5 = nn.Conv2d(2048, 64, kernel_size=1, stride=1, padding=0)\n",
        "      \n",
        "      #32 64 128 256\n",
        "      \n",
        "      for p in self.layer1.parameters():\n",
        "        p.requires_grad = False\n",
        "  \n",
        "      for p in self.layer2.parameters():\n",
        "        p.requires_grad = False\n",
        "        \n",
        "    #  for p in self.layer3.parameters():\n",
        "    #    p.requires_grad = False\n",
        "\n",
        "    anchor_areas = [ 64*64., 128*128., 256*256., 512*512.] \n",
        "    aspect_ratios = [1/1.,1/2., 2/1.]\n",
        "    scale_ratios = [1., 1./pow(2.,1/3.), 1./pow(2.,2/3.)]\n",
        "    anchor_base_sizes = [8., 16., 32., 64. ]\n",
        "    self.anchor_gen = Anchor(anchor_areas=anchor_areas,\n",
        "                            aspect_ratios= aspect_ratios,\n",
        "                            scale_ratios = scale_ratios,\n",
        "                            anchor_base_sizes = anchor_base_sizes)\n",
        "        \n",
        "    num_anchors = self.anchor_gen.num_anchors\n",
        "        \n",
        "    self.loc_head_l = self._make_head_layer(256+35, 256, 3)\n",
        "    self.cls_head_l = self._make_head_layer(256+35, 256, 3)\n",
        "    self.loc_head_s = self._make_head_layer(256+35, 256, 3)\n",
        "    self.cls_head_s = self._make_head_layer(256+35, 256, 3)\n",
        "    \n",
        "    if self.class_agnostic:\n",
        "      loc_out_plane = num_anchors * 4\n",
        "    else:\n",
        "      loc_out_plane = num_anchors * 4 * num_classes\n",
        "    self.loc_l = nn.Conv2d(256, loc_out_plane, 3, 1, 1)\n",
        "    self.cls_l = nn.Conv2d(256, num_anchors * (num_classes+1), 3, 1, 1)\n",
        "    self.loc_s = nn.Conv2d(256, loc_out_plane, 3, 1, 1)\n",
        "    self.cls_s = nn.Conv2d(256, num_anchors * (num_classes+1), 3, 1, 1)\n",
        "    \n",
        "    self._normal_init(self.loc_head_l)\n",
        "    self._normal_init(self.cls_head_l)\n",
        "    self._normal_init(self.loc_head_s)\n",
        "    self._normal_init(self.cls_head_s)\n",
        "    self._normal_init(self.latlayer4)\n",
        "    self._normal_init(self.latlayer3)\n",
        "    self._normal_init(self.toplayer3)\n",
        "    self._normal_init(self.latlayer2)\n",
        "    self._normal_init(self.toplayer2)\n",
        "    self._normal_init(self.conv5)\n",
        "    self._normal_init(self.rconv1)\n",
        "    self._normal_init(self.rconv3)\n",
        "    self._normal_init(self.rconv5)\n",
        "    \n",
        "    self.loc_l.weight.data.normal_(0.0, 0.001)\n",
        "    self.loc_l.bias.data.zero_()\n",
        "    self.cls_l.weight.data.normal_(0.0, 0.01)\n",
        "    self.cls_l.bias.data.zero_()\n",
        "    self.loc_s.weight.data.normal_(0.0, 0.001)\n",
        "    self.loc_s.bias.data.zero_()\n",
        "    self.cls_s.weight.data.normal_(0.0, 0.01)\n",
        "    self.cls_s.bias.data.zero_()\n",
        "    \n",
        "  def _make_head_layer(self, in_plane, h_plane, num_itr):\n",
        "    head_layer = []\n",
        "    head_layer.append(nn.Conv2d(in_plane, h_plane, 3, 1, 1))\n",
        "    head_layer.append(nn.ReLU(True))\n",
        "    for _ in range(num_itr):\n",
        "      head_layer.append(nn.Conv2d(h_plane, h_plane, 3, 1, 1))\n",
        "      head_layer.append(nn.ReLU(True))\n",
        "    \n",
        "    return nn.Sequential(*head_layer)\n",
        "  \n",
        "  def _normal_init(self, layer):\n",
        "    for m in layer.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "              \n",
        "  def _upsample_add(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    return nn.functional.interpolate(x, size=(H,W), mode='bilinear') + y\n",
        "  \n",
        "  def _upsample_cat(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    layers = []\n",
        "    layers.append(y)\n",
        "    for sx in x:\n",
        "       layers.append(nn.functional.interpolate(sx, size=(H,W), mode='bilinear'))\n",
        "    return torch.cat(layers,1)\n",
        "    \n",
        "  def train(self, mode=True):\n",
        "    super(GCDet, self).train(mode)\n",
        "    #freeze bn\n",
        "    if self.model == 'resnet':\n",
        "      if mode:\n",
        "        for layer in self.modules():\n",
        "          if isinstance(layer, nn.BatchNorm2d):\n",
        "            layer.eval()\n",
        "            \n",
        "\n",
        "    \n",
        "  def forward(self,x):\n",
        "    c1 = self.layer1(x)\n",
        "    c2 = self.layer2(c1) #8\n",
        "    c3 = self.layer3(c2) #16\n",
        "    c4 = self.layer4(c3) #32\n",
        "    \n",
        "    p5 = self.conv5(c4) #64\n",
        "    p4 = self.latlayer4(c4)\n",
        "    p3 = self._upsample_add(p4, self.latlayer3(c3))\n",
        "    p3 = self.toplayer3(p3)\n",
        "    p2 = self._upsample_add(p3, self.latlayer2(c2))\n",
        "    p2 = self.toplayer2(p2)\n",
        "    \n",
        "    rmap1x1 = self.rconv1(self.avg_pool_1x1(c4))\n",
        "    rmap3x3 = self.rconv3(self.avg_pool_3x3(c4))\n",
        "    rmap5x5 = self.rconv5(self.avg_pool_5x5(c4))\n",
        "    rmap1x1 = rmap1x1.permute(0,2,3,1).contiguous().view(rmap1x1.size(0),-1,8,8)\n",
        "    rmap3x3 = rmap3x3.permute(0,2,3,1).contiguous().view(rmap3x3.size(0),-1,8,8)\n",
        "    rmap5x5 = rmap5x5.permute(0,2,3,1).contiguous().view(rmap5x5.size(0),-1,8,8)\n",
        "    \n",
        "    \n",
        "    p2 = self._upsample_cat([rmap1x1,rmap3x3,rmap5x5],p2)\n",
        "    p3 = self._upsample_cat([rmap1x1,rmap3x3,rmap5x5],p3)\n",
        "    p4 = self._upsample_cat([rmap1x1,rmap3x3,rmap5x5],p4)\n",
        "    p5 = self._upsample_cat([rmap1x1,rmap3x3,rmap5x5],p5)\n",
        "    \n",
        "    pred_locs = []\n",
        "    pred_clss = []\n",
        "    fm_size = []\n",
        "    for fm_idx, fm in enumerate([p2,p3,p4,p5]):\n",
        "      if fm_idx >= 2:\n",
        "        loc_h = self.loc_head_l(fm)\n",
        "        cls_h = self.cls_head_l(fm) \n",
        "        pred_loc = self.loc_l(loc_h)\n",
        "        pred_cls = self.cls_l(cls_h)\n",
        "      else:\n",
        "        loc_h = self.loc_head_s(fm)\n",
        "        cls_h = self.cls_head_s(fm) \n",
        "        pred_loc = self.loc_s(loc_h)\n",
        "        pred_cls = self.cls_s(cls_h)\n",
        "        \n",
        "      if self.class_agnostic:\n",
        "        pred_loc = pred_loc.permute(0, 2, 3, 1).contiguous().view(pred_loc.size(0), -1, 4)\n",
        "      else:\n",
        "        pred_loc = pred_loc.permute(0, 2, 3, 1).contiguous().view(pred_loc.size(0), -1, 4 * self.num_classes)\n",
        "      pred_cls = pred_cls.permute(0, 2, 3, 1).contiguous().view(pred_cls.size(0), -1, self.num_classes+1)\n",
        "    \n",
        "      pred_locs.append(pred_loc)\n",
        "      pred_clss.append(pred_cls)\n",
        "      fm_size.append(fm.size())\n",
        "    pred_locs = torch.cat(pred_locs,1)\n",
        "    pred_clss = torch.cat(pred_clss,1)\n",
        "    anchor = self.anchor_gen.get_anchor_boxes(fm_size)\n",
        "    \n",
        "    return pred_locs, pred_clss,anchor\n",
        "    \n",
        "#device = torch.device('cuda')\n",
        "\n",
        "def testgc():\n",
        "  x = torch.randn((1,3,600,900))\n",
        "  model = GCDet(6)\n",
        "  x = x.to(device)\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  pred_loc,pred_cls,anchor = model(x)\n",
        "  print(pred_loc[0].size())\n",
        "  print(pred_cls[0].size())\n",
        "  print(anchor.size())\n",
        "  print(anchor[0])\n",
        "  print(anchor[9])\n",
        "  print(anchor[18])\n",
        "  print(anchor[57*9])\n",
        "  print(anchor[57*9+9])\n",
        "  print(anchor[57*9-9])\n",
        "  \n",
        "testgc()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-56., -56.,  71.,  71.])\n",
            "tensor([-40., -56.,  87.,  71.])\n",
            "tensor([-24., -56., 103.,  71.])\n",
            "tensor([-56., -40.,  71.,  87.])\n",
            "tensor([-56., -56.,  71.,  71.])\n",
            "tensor([-40., -56.,  87.,  71.])\n",
            "tensor([-24., -56., 103.,  71.])\n",
            "tensor([ -8., -56., 119.,  71.])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
            "100%|██████████| 102502400/102502400 [00:03<00:00, 28015792.04it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([102078, 24])\n",
            "torch.Size([102078, 7])\n",
            "torch.Size([102078, 4])\n",
            "tensor([-28., -28.,  35.,  35.])\n",
            "tensor([-20., -28.,  43.,  35.])\n",
            "tensor([-12., -28.,  51.,  35.])\n",
            "tensor([428., -28., 491.,  35.])\n",
            "tensor([436., -28., 499.,  35.])\n",
            "tensor([420., -28., 483.,  35.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qiweskOKsBoY",
        "colab_type": "code",
        "outputId": "80958fd5-4d92-4ed6-cb17-1ab710583ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import vgg16,squeezenet1_1\n",
        "from anchor import Anchor\n",
        "\n",
        "device=torch.device('cpu')\n",
        "\n",
        "class GCDet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes, model='resnet', class_agnostic=False):\n",
        "    super(GCDet, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.model = model\n",
        "    self.class_agnostic=class_agnostic\n",
        "    \n",
        "    if model == 'resnet':\n",
        "      model_name = 'resnet50' \n",
        "      \n",
        "      base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "      self.layer1 = nn.Sequential(base_model.conv1,base_model.bn1,base_model.relu,base_model.maxpool, base_model.layer1)\n",
        "      self.layer2 = base_model.layer2\n",
        "      self.layer3 = base_model.layer3\n",
        "      self.layer4 = base_model.layer4\n",
        "      self.latlayer4 = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.latlayer3 = nn.Conv2d(1024, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.toplayer3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "      self.latlayer2 = nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0)\n",
        "      self.toplayer2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "      self.conv5 = nn.Conv2d(2048, 256, kernel_size=3, stride=2, padding=1)\n",
        "      self.avg_pool_1x1 = nn.AdaptiveAvgPool2d((1,1))\n",
        "#      self.avg_pool_3x3 = nn.AdaptiveAvgPool2d((3,3))\n",
        "#      self.avg_pool_5x5 = nn.AdaptiveAvgPool2d((5,5))\n",
        "      self.rconv1 = nn.Conv2d(2048, 12, kernel_size=1, stride=1, padding=0)\n",
        "#      self.rconv3 = nn.Conv2d(2048, 12, kernel_size=1, stride=1, padding=0)\n",
        "#      self.rconv5 = nn.Conv2d(2048, 12, kernel_size=1, stride=1, padding=0)\n",
        "      \n",
        "      #32 64 128 256\n",
        "      \n",
        "      for p in self.layer1.parameters():\n",
        "        p.requires_grad = False\n",
        "  \n",
        "      for p in self.layer2.parameters():\n",
        "        p.requires_grad = False\n",
        "        \n",
        "    #  for p in self.layer3.parameters():\n",
        "    #    p.requires_grad = False\n",
        "\n",
        "    anchor_areas = [ 64*64., 128*128., 256*256., 512*512.] \n",
        "    aspect_ratios = [1/1.,1/2., 2/1.]\n",
        "    scale_ratios = [1., 1./pow(2.,1/3.), 1./pow(2.,2/3.)]\n",
        "    anchor_base_sizes = [8., 16., 32., 64. ]\n",
        "    self.anchor_gen = Anchor(anchor_areas=anchor_areas,\n",
        "                            aspect_ratios= aspect_ratios,\n",
        "                            scale_ratios = scale_ratios,\n",
        "                            anchor_base_sizes = anchor_base_sizes)\n",
        "        \n",
        "    num_anchors = self.anchor_gen.num_anchors\n",
        "\n",
        "    self.ar_loc_head = self._make_head_layer(256+1, 256, 3)\n",
        "    self.ar_cls_head = self._make_head_layer(256+1, 256, 3)\n",
        "    self.ar_loc_relu = nn.ReLU(True)\n",
        "    self.ar_cls_relu = nn.ReLU(True)\n",
        "    self.ar_loc = nn.Conv2d(256, num_anchors * 4, 3, 1, 1)\n",
        "    self.ar_cls = nn.Conv2d(256, num_anchors * 2, 3, 1, 1)\n",
        "    \n",
        "    \n",
        "    self.loc_head = self._make_head_layer(256, 256, 4)\n",
        "    self.cls_head = self._make_head_layer(256, 256, 4)\n",
        "#    self.loc_head_s = self._make_head_layer(256+1, 256, 3)\n",
        "#    self.cls_head_s = self._make_head_layer(256+1, 256, 3)\n",
        "    \n",
        "    if self.class_agnostic:\n",
        "      loc_out_plane = num_anchors * 4\n",
        "    else:\n",
        "      loc_out_plane = num_anchors * 4 * num_classes\n",
        "    self.loc = nn.Conv2d(256, loc_out_plane, 3, 1, 1)\n",
        "    self.cls = nn.Conv2d(256, num_anchors * (num_classes+1), 3, 1, 1)\n",
        "#    self.loc_s = nn.Conv2d(256, loc_out_plane, 3, 1, 1)\n",
        "#    self.cls_s = nn.Conv2d(256, num_anchors * (num_classes+1), 3, 1, 1)\n",
        "    \n",
        "    self._normal_init(self.ar_loc_head)\n",
        "    self._normal_init(self.ar_cls_head)\n",
        "    self._normal_init(self.loc_head)\n",
        "    self._normal_init(self.cls_head)\n",
        "#    self._normal_init(self.loc_head_s)\n",
        "#    self._normal_init(self.cls_head_s)\n",
        "    self._normal_init(self.latlayer4)\n",
        "    self._normal_init(self.latlayer3)\n",
        "    self._normal_init(self.toplayer3)\n",
        "    self._normal_init(self.latlayer2)\n",
        "    self._normal_init(self.toplayer2)\n",
        "    self._normal_init(self.conv5)\n",
        "    self._normal_init(self.rconv1)\n",
        "#    self._normal_init(self.rconv3)\n",
        "#    self._normal_init(self.rconv5)\n",
        "\n",
        "    self.ar_loc.weight.data.normal_(0.0, 0.001)\n",
        "    self.ar_loc.bias.data.zero_()\n",
        "    self.ar_cls.weight.data.normal_(0.0, 0.01)\n",
        "    self.ar_cls.bias.data.zero_()\n",
        "    self.loc.weight.data.normal_(0.0, 0.001)\n",
        "    self.loc.bias.data.zero_()\n",
        "    self.cls.weight.data.normal_(0.0, 0.01)\n",
        "    self.cls.bias.data.zero_()\n",
        "#    self.loc_s.weight.data.normal_(0.0, 0.001)\n",
        "#    self.loc_s.bias.data.zero_()\n",
        "#    self.cls_s.weight.data.normal_(0.0, 0.01)\n",
        "#    self.cls_s.bias.data.zero_()\n",
        "    \n",
        "  def _make_head_layer(self, in_plane, h_plane, num_itr):\n",
        "    head_layer = []\n",
        "    \n",
        "    for i in range(num_itr):\n",
        "      if i == 0:\n",
        "        head_layer.append(nn.Conv2d(in_plane, h_plane, 3, 1, 1))\n",
        "      else:\n",
        "        head_layer.append(nn.Conv2d(h_plane, h_plane, 3, 1, 1))\n",
        "      head_layer.append(nn.ReLU(True))\n",
        "    \n",
        "    return nn.Sequential(*head_layer)\n",
        "  \n",
        "  def _normal_init(self, layer):\n",
        "    for m in layer.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "              \n",
        "  def _upsample_add(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    return nn.functional.interpolate(x, size=(H,W), mode='bilinear') + y\n",
        "  \n",
        "  def _upsample_cat(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    layers = []\n",
        "    layers.append(y)\n",
        "    for sx in x:\n",
        "       layers.append(nn.functional.interpolate(sx, size=(H,W), mode='bilinear'))\n",
        "    return torch.cat(layers,1)\n",
        "    \n",
        "  def train(self, mode=True):\n",
        "    super(GCDet, self).train(mode)\n",
        "    #freeze bn\n",
        "    if self.model == 'resnet':\n",
        "      if mode:\n",
        "        for layer in self.modules():\n",
        "          if isinstance(layer, nn.BatchNorm2d):\n",
        "            layer.eval()\n",
        "            \n",
        "\n",
        "    \n",
        "  def forward(self,x):\n",
        "    c1 = self.layer1(x)\n",
        "    c2 = self.layer2(c1) #8\n",
        "    c3 = self.layer3(c2) #16\n",
        "    c4 = self.layer4(c3) #32\n",
        "    \n",
        "    p5 = self.conv5(c4) #64\n",
        "    p4 = self.latlayer4(c4)\n",
        "    p3 = self._upsample_add(p4, self.latlayer3(c3))\n",
        "    p3 = self.toplayer3(p3)\n",
        "    p2 = self._upsample_add(p3, self.latlayer2(c2))\n",
        "    p2 = self.toplayer2(p2)\n",
        "    \n",
        "    rmap1x1 = self.rconv1(self.avg_pool_1x1(c4))\n",
        "    #rmap3x3 = self.rconv3(self.avg_pool_3x3(c4))\n",
        "    #rmap5x5 = self.rconv5(self.avg_pool_5x5(c4))\n",
        "    rmap1x1 = rmap1x1.permute(0,2,3,1).contiguous().view(rmap1x1.size(0),-1,3,4)\n",
        "    #rmap3x3 = rmap3x3.permute(0,2,3,1).contiguous().view(rmap3x3.size(0),-1,3,4)\n",
        "    #rmap5x5 = rmap5x5.permute(0,2,3,1).contiguous().view(rmap5x5.size(0),-1,3,4)\n",
        "    \n",
        "    p2 = self._upsample_cat([rmap1x1],p2)\n",
        "    p3 = self._upsample_cat([rmap1x1],p3)\n",
        "    p4 = self._upsample_cat([rmap1x1],p4)\n",
        "    p5 = self._upsample_cat([rmap1x1],p5)\n",
        "    \n",
        "    ar_locs = []\n",
        "    ar_clss = []\n",
        "    pred_locs = []\n",
        "    pred_clss = []\n",
        "    fm_size = []\n",
        "    for fm_idx, fm in enumerate([p2,p3,p4,p5]):\n",
        "      \n",
        "      ar_loc_h = self.ar_loc_head(fm)\n",
        "      ar_cls_h = self.ar_cls_head(fm)\n",
        "      pred_ar_loc = self.ar_loc(ar_loc_h)\n",
        "      pred_ar_cls = self.ar_cls(ar_cls_h)\n",
        "      pred_ar_loc = pred_ar_loc.permute(0, 2, 3, 1).contiguous().view(pred_ar_loc.size(0), -1, 4)\n",
        "      pred_ar_cls = pred_ar_cls.permute(0, 2, 3, 1).contiguous().view(pred_ar_cls.size(0), -1, 2)\n",
        "      \n",
        "     # loc_h = self.loc_head(fm)\n",
        "     # cls_h = self.cls_head(fm) \n",
        "      loc_h = self.loc_head(self.ar_loc_relu(ar_loc_h))\n",
        "      cls_h = self.cls_head(self.ar_cls_relu(ar_cls_h)) \n",
        "      pred_loc = self.loc(loc_h)\n",
        "      pred_cls = self.cls(cls_h)\n",
        "        \n",
        "      if self.class_agnostic:\n",
        "        pred_loc = pred_loc.permute(0, 2, 3, 1).contiguous().view(pred_loc.size(0), -1, 4)\n",
        "      else:\n",
        "        pred_loc = pred_loc.permute(0, 2, 3, 1).contiguous().view(pred_loc.size(0), -1, 4 * self.num_classes)\n",
        "      pred_cls = pred_cls.permute(0, 2, 3, 1).contiguous().view(pred_cls.size(0), -1, self.num_classes+1)\n",
        "    \n",
        "      pred_locs.append(pred_loc)\n",
        "      pred_clss.append(pred_cls)\n",
        "      ar_locs.append(pred_ar_loc)\n",
        "      ar_clss.append(pred_ar_cls)\n",
        "      fm_size.append(fm.size())\n",
        "    pred_locs = torch.cat(pred_locs,1)\n",
        "    pred_clss = torch.cat(pred_clss,1)\n",
        "    ar_locs = torch.cat(ar_locs,1)\n",
        "    ar_clss = torch.cat(ar_clss,1)\n",
        "    anchor = self.anchor_gen.get_anchor_boxes(fm_size)\n",
        "    \n",
        "    return pred_locs, pred_clss, anchor, ar_locs, ar_clss\n",
        "  \n",
        "def testgc():\n",
        "  x = torch.randn((1,3,600,900))\n",
        "  model = GCDet(6)\n",
        "  x = x.to(device)\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  pred_loc,pred_cls,anchor, ar_loc, ar_cls = model(x)\n",
        "  print(pred_loc[0].size())\n",
        "  print(pred_cls[0].size())\n",
        "  print(ar_loc[0].size())\n",
        "  print(ar_cls[0].size())\n",
        "  print(anchor.size())\n",
        "  print(anchor[0])\n",
        "  print(anchor[9])\n",
        "  print(anchor[18])\n",
        "  print(anchor[57*9])\n",
        "  print(anchor[57*9+9])\n",
        "  print(anchor[57*9-9])\n",
        "\n",
        "testgc()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([102078, 24])\n",
            "torch.Size([102078, 7])\n",
            "torch.Size([102078, 4])\n",
            "torch.Size([102078, 2])\n",
            "torch.Size([102078, 4])\n",
            "tensor([-28., -28.,  35.,  35.])\n",
            "tensor([-20., -28.,  43.,  35.])\n",
            "tensor([-12., -28.,  51.,  35.])\n",
            "tensor([428., -28., 491.,  35.])\n",
            "tensor([436., -28., 499.,  35.])\n",
            "tensor([420., -28., 483.,  35.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1haFg05qBrrf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class L2Norm(nn.Module):\n",
        "    def __init__(self,n_channels, scale):\n",
        "        super(L2Norm,self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.gamma = scale or None\n",
        "        self.eps = 1e-10\n",
        "        self.weight = nn.Parameter(torch.Tensor(self.n_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.constant(self.weight,self.gamma)\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt()+self.eps\n",
        "        x /= norm\n",
        "        out = self.weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x) * x\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pST4WBGvc6bi",
        "colab_type": "code",
        "outputId": "7ff48762-a575-4ae8-9f82-fecf245091f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "cell_type": "code",
      "source": [
        "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
        "from anchor import Anchor\n",
        "import pretrainedmodels\n",
        "device = torch.device('cpu')\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "  \"\"\"1x1 convolution\"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class GCRefDet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes, model='resnet18', class_agnostic=False):\n",
        "    super(GCRefDet, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.model = model\n",
        "    self.class_agnostic=class_agnostic\n",
        "    \n",
        "    if (model == 'resnet18') or (model == 'resnet34') :\n",
        "      model_name = model \n",
        "      layer5_num = 2\n",
        "      plane_size = [128,256,512,512]\n",
        "      self.inplanes = 512\n",
        "      self.layer5 = self._make_residual_layer(BasicBlock, 512, layer5_num, stride=2) #1/64\n",
        "      base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "      self.layer1 = nn.Sequential(base_model.conv1,base_model.bn1,base_model.relu,base_model.maxpool, base_model.layer1) #1/4\n",
        "      \n",
        "    elif model == 'senet':\n",
        "      model_name = 'se_resnext50_32x4d'\n",
        "      layer5_num = 3\n",
        "      plane_size = [512,1024,2048,512]\n",
        "      self.inplanes = 2048\n",
        "      self.layer5 = self._make_residual_layer(Bottleneck, 128, layer5_num, stride=2) #1/64\n",
        "      base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "      self.layer1 = nn.Sequential(base_model.layer0, base_model.layer1) #1/4\n",
        "  \n",
        "\n",
        "    self.layer2 = base_model.layer2 #1/8\n",
        "    self.layer3 = base_model.layer3 #1/16\n",
        "    self.layer4 = base_model.layer4 #1/32\n",
        "     \n",
        "      \n",
        "      \n",
        "    for p in self.layer1.parameters():\n",
        "      p.requires_grad = False\n",
        "  \n",
        "    for p in self.layer2.parameters():\n",
        "      p.requires_grad = False\n",
        "        \n",
        "    for p in self.layer3.parameters():\n",
        "      p.requires_grad = False\n",
        "\n",
        "    anchor_areas = [ 32*32., 64*64., 128*128., 256*256.] \n",
        "    aspect_ratios = [1/1.,1/2., 2/1.]\n",
        "    scale_ratios = [1.]\n",
        "    anchor_base_sizes = [8., 16., 32., 64. ]\n",
        "    self.anchor_gen = Anchor(anchor_areas=anchor_areas,\n",
        "                            aspect_ratios= aspect_ratios,\n",
        "                            scale_ratios = scale_ratios,\n",
        "                            anchor_base_sizes = anchor_base_sizes)\n",
        "        \n",
        "    num_anchors = self.anchor_gen.num_anchors\n",
        "\n",
        "    self.ar_loc_heads = nn.ModuleList([\n",
        "        self._make_head_layer(plane_size[0], num_anchors * 4),\n",
        "        self._make_head_layer(plane_size[1], num_anchors * 4),\n",
        "        self._make_head_layer(plane_size[2], num_anchors * 4),\n",
        "        self._make_head_layer(plane_size[3], num_anchors * 4)\n",
        "    ])\n",
        "    \n",
        "    self.ar_cls_heads = nn.ModuleList([\n",
        "        self._make_head_layer(plane_size[0], num_anchors * 2),\n",
        "        self._make_head_layer(plane_size[1], num_anchors * 2),\n",
        "        self._make_head_layer(plane_size[2], num_anchors * 2),\n",
        "        self._make_head_layer(plane_size[3], num_anchors * 2)\n",
        "    ])\n",
        "    \n",
        "    self.od_loc_heads = nn.ModuleList([\n",
        "        self._make_head_layer(256, num_anchors * 4),\n",
        "        self._make_head_layer(256, num_anchors * 4),\n",
        "        self._make_head_layer(256, num_anchors * 4),\n",
        "        self._make_head_layer(256, num_anchors * 4)\n",
        "    ])\n",
        "    \n",
        "    self.od_cls_heads = nn.ModuleList([\n",
        "        self._make_head_layer(256, num_anchors * (num_classes+1)),\n",
        "        self._make_head_layer(256, num_anchors * (num_classes+1)),\n",
        "        self._make_head_layer(256, num_anchors * (num_classes+1)),\n",
        "        self._make_head_layer(256, num_anchors * (num_classes+1))\n",
        "    ])\n",
        "    \n",
        "    self.trans4 = nn.Sequential(nn.Conv2d(plane_size[3], 256, kernel_size=3, stride=1, padding=1),\n",
        "                                                     nn.ReLU(inplace=True),\n",
        "                                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1))\n",
        "    self.trans3 = nn.Sequential(nn.Conv2d(plane_size[2], 256, kernel_size=3, stride=1, padding=1),\n",
        "                                                     nn.ReLU(inplace=True),\n",
        "                                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1))\n",
        "    self.trans2 = nn.Sequential(nn.Conv2d(plane_size[1], 256, kernel_size=3, stride=1, padding=1),\n",
        "                                                     nn.ReLU(inplace=True),\n",
        "                                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1))\n",
        "    self.trans1 =  nn.Sequential(nn.Conv2d(plane_size[0], 256, kernel_size=3, stride=1, padding=1),\n",
        "                                                     nn.ReLU(inplace=True),\n",
        "                                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1))\n",
        "                                     \n",
        "    self.up4 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2, padding=0)\n",
        "    self.up3 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2, padding=0)\n",
        "    self.up2 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    self.latent4 = nn.Sequential(nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True))\n",
        "    self.latent3 = nn.Sequential(nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True))\n",
        "    self.latent2 = nn.Sequential(nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True))\n",
        "    self.latent1 = nn.Sequential(nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True))\n",
        "       \n",
        "    self._normal_init(self.layer5)\n",
        "    self._normal_init(self.ar_loc_heads)\n",
        "    self._normal_init(self.ar_cls_heads)\n",
        "    self._normal_init(self.od_loc_heads)\n",
        "    self._normal_init(self.od_cls_heads)\n",
        "    self._normal_init(self.trans4)\n",
        "    self._normal_init(self.trans3)\n",
        "    self._normal_init(self.trans2)\n",
        "    self._normal_init(self.trans1)\n",
        "    self._normal_init(self.up4)\n",
        "    self._normal_init(self.up3)\n",
        "    self._normal_init(self.up2)\n",
        "    self._normal_init(self.latent4)\n",
        "    self._normal_init(self.latent3)\n",
        "    self._normal_init(self.latent2)\n",
        "    self._normal_init(self.latent1)\n",
        "    \n",
        "\n",
        "  def _make_residual_layer(self, block, planes, blocks, stride=1):\n",
        "    downsample = None\n",
        "    if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "        downsample = nn.Sequential(\n",
        "            conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "            nn.BatchNorm2d(planes * block.expansion),\n",
        "        )\n",
        "\n",
        "    layers = []\n",
        "    layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "    self.inplanes = planes * block.expansion\n",
        "    for _ in range(1, blocks):\n",
        "        layers.append(block(self.inplanes, planes))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "  \n",
        "  def _make_head_layer(self, in_planes, out_planes, planes = 0, num_itr = 0):\n",
        "    head_layer = []\n",
        "    \n",
        "    if(num_itr > 0):\n",
        "      head_layer.append(nn.Conv2d(in_planes, planes, 3, 1, 1))\n",
        "      head_layer.append(nn.ReLU(True))\n",
        "      for i in range(1,num_itr):\n",
        "        if i == num_itr - 1:\n",
        "          head_layer.append(nn.Conv2d(planes, out_planes, 3, 1, 1))\n",
        "        else:\n",
        "          head_layer.append(nn.Conv2d(planes, planes, 3, 1, 1))\n",
        "          head_layer.append(nn.ReLU(True))\n",
        "    else:\n",
        "      head_layer.append(nn.Conv2d(in_planes, out_planes, 3, 1, 1))\n",
        "    \n",
        "    return nn.Sequential(*head_layer)\n",
        "  \n",
        "  def _normal_init(self, layer):\n",
        "    for m in layer.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "      if isinstance(m, nn.ConvTranspose2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "      if isinstance(m, Bottleneck):\n",
        "          nn.init.constant_(m.bn3.weight, 0)\n",
        "      elif isinstance(m, BasicBlock):\n",
        "          nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "              \n",
        "  def _upsample_add(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    return nn.functional.interpolate(x, size=(H,W), mode='bilinear') + y\n",
        "  \n",
        "  def _upsample_cat(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    layers = []\n",
        "    layers.append(y)\n",
        "    for sx in x:\n",
        "       layers.append(nn.functional.interpolate(sx, size=(H,W), mode='bilinear'))\n",
        "    return torch.cat(layers,1)\n",
        "    \n",
        "  def train(self, mode=True):\n",
        "    super(GCRefDet, self).train(mode)\n",
        "    #freeze bn\n",
        "    #if self.model == 'resnet18':\n",
        "    #  if mode:\n",
        "    #    for layer in self.modules():\n",
        "    #      if isinstance(layer, nn.BatchNorm2d):\n",
        "    #        layer.eval()\n",
        "            \n",
        "\n",
        "    \n",
        "  def forward(self,x):\n",
        "    c1 = self.layer1(x)\n",
        "    c2 = self.layer2(c1) #8\n",
        "    c3 = self.layer3(c2) #16\n",
        "    c4 = self.layer4(c3) #32\n",
        "    c5 = self.layer5(c4) #64\n",
        " \n",
        "    ar_locs = []\n",
        "    ar_clss = []\n",
        "    fm_size = []\n",
        "    for fm, ar_loc_head, ar_cls_head in zip([c2,c3,c4,c5], self.ar_loc_heads, self.ar_cls_heads):\n",
        "      ar_loc_h = ar_loc_head(fm)\n",
        "      ar_cls_h = ar_cls_head(fm)\n",
        "      ar_loc_h = ar_loc_h.permute(0, 2, 3, 1).contiguous().view(fm.size(0), -1, 4)\n",
        "      ar_cls_h = ar_cls_h.permute(0, 2, 3, 1).contiguous().view(fm.size(0), -1, 2)\n",
        "      ar_locs.append(ar_loc_h)\n",
        "      ar_clss.append(ar_cls_h)\n",
        "      fm_size.append(fm.size())\n",
        "    ar_locs = torch.cat(ar_locs,1)\n",
        "    ar_clss = torch.cat(ar_clss,1)\n",
        "    anchor = self.anchor_gen.get_anchor_boxes(fm_size)\n",
        "    \n",
        "    o4 = self.latent4(self.trans4(c5))\n",
        "    o3 = self.latent3(self.trans3(c4) + self.up4(o4))\n",
        "    o2 = self.latent2(self.trans2(c3) + self.up3(o3))\n",
        "    o1 = self.latent1(self.trans1(c2) + self.up2(o2))\n",
        "    \n",
        "    od_locs = []\n",
        "    od_clss = []\n",
        "    for fm, od_loc_head, od_cls_head in zip([o1,o2,o3,o4], self.od_loc_heads, self.od_cls_heads):\n",
        "      od_loc_h = od_loc_head(fm)\n",
        "      od_cls_h = od_cls_head(fm)\n",
        "      od_loc_h = od_loc_h.permute(0, 2, 3, 1).contiguous().view(fm.size(0), -1, 4)\n",
        "      od_cls_h = od_cls_h.permute(0, 2, 3, 1).contiguous().view(fm.size(0), -1, self.num_classes+1)\n",
        "      od_locs.append(od_loc_h)\n",
        "      od_clss.append(od_cls_h)\n",
        "    od_locs = torch.cat(od_locs,1)\n",
        "    od_clss = torch.cat(od_clss,1)\n",
        "    \n",
        "    return ar_locs, ar_clss, od_locs, od_clss, anchor\n",
        "  \n",
        "def testgc():\n",
        "  x = torch.randn((1,3, 576, 960))\n",
        "  model = GCRefDet(6,model='senet')\n",
        "  x = x.to(device)\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  ar_loc, ar_cls, od_loc, od_cls, anchor = model(x)\n",
        "  print(ar_loc[0].size())\n",
        "  print(ar_cls[0].size())\n",
        "  print(od_loc[0].size())\n",
        "  print(od_cls[0].size())\n",
        "  print(anchor.size())\n",
        "  print(anchor[0])\n",
        "  print(anchor[9])\n",
        "  print(anchor[18])\n",
        "  print(anchor[57*9])\n",
        "  print(anchor[57*9+9])\n",
        "  print(anchor[57*9-9])\n",
        "\n",
        "testgc()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([34425, 4])\n",
            "torch.Size([34425, 2])\n",
            "torch.Size([34425, 4])\n",
            "torch.Size([34425, 7])\n",
            "torch.Size([34425, 4])\n",
            "tensor([-12., -12.,  19.,  19.])\n",
            "tensor([ 12., -12.,  43.,  19.])\n",
            "tensor([ 36., -12.,  67.,  19.])\n",
            "tensor([396.,  -4., 427.,  27.])\n",
            "tensor([420.,  -4., 451.,  27.])\n",
            "tensor([372.,  -4., 403.,  27.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MDiNnRLPT8J2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(1,1):\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "enuBYXkQUAk8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "266pbsVdvVQT",
        "colab_type": "code",
        "outputId": "e815a06f-a2f9-4701-926e-cdb86d52cd8b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-806ee6be-f137-4b56-8dd5-86039a03e790\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-806ee6be-f137-4b56-8dd5-86039a03e790\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving anchor.py to anchor.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hgwih7K-PRb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "7bc0d1e7-4a1a-4dec-b76c-a20539661679",
        "id": "2XjtgxEg6fPb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "cell_type": "code",
      "source": [
        "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
        "from anchor import Anchor\n",
        "import pretrainedmodels\n",
        "device = torch.device('cpu')\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "  \"\"\"1x1 convolution\"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class GCRefDet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes, model='resnet18', class_agnostic=False):\n",
        "    super(GCRefDet, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.model = model\n",
        "    self.class_agnostic=class_agnostic\n",
        "    \n",
        "    if (model == 'resnet18') or (model == 'resnet34') :\n",
        "      model_name = model \n",
        "      layer5_num = 2\n",
        "      plane_size = [128,256,512,512]\n",
        "      self.inplanes = 512\n",
        "      self.layer5 = self._make_residual_layer(BasicBlock, 512, layer5_num, stride=2) #1/64\n",
        "      base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "      self.layer1 = nn.Sequential(base_model.conv1,base_model.bn1,base_model.relu,base_model.maxpool, base_model.layer1) #1/4\n",
        "      \n",
        "    elif model == 'senet':\n",
        "      model_name = 'se_resnext50_32x4d'\n",
        "      layer5_num = 3\n",
        "      plane_size = [512,1024,2048,512]\n",
        "      self.inplanes = 2048\n",
        "      self.layer5 = self._make_residual_layer(Bottleneck, 128, layer5_num, stride=2) #1/64\n",
        "      base_model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "      self.layer1 = nn.Sequential(base_model.layer0, base_model.layer1) #1/4\n",
        "  \n",
        "\n",
        "    self.layer2 = base_model.layer2 #1/8\n",
        "    self.layer3 = base_model.layer3 #1/16\n",
        "    self.layer4 = base_model.layer4 #1/32\n",
        "     \n",
        "      \n",
        "      \n",
        "    for p in self.layer1.parameters():\n",
        "      p.requires_grad = False\n",
        "  \n",
        "    for p in self.layer2.parameters():\n",
        "      p.requires_grad = False\n",
        "        \n",
        "    for p in self.layer3.parameters():\n",
        "      p.requires_grad = False\n",
        "      \n",
        "    for p in self.layer4.parameters():\n",
        "      p.requires_grad = False\n",
        "\n",
        "    anchor_areas = [ 64*64., 128*128., 256*256., 512*512.] \n",
        "    aspect_ratios = [1/1.,1/2., 2/1.]\n",
        "    scale_ratios = [1., 1./pow(2.,1/3.), 1./pow(2.,2/3.)]\n",
        "    anchor_base_sizes = [8., 16., 32., 64. ]\n",
        "    self.anchor_gen = Anchor(anchor_areas=anchor_areas,\n",
        "                            aspect_ratios= aspect_ratios,\n",
        "                            scale_ratios = scale_ratios,\n",
        "                            anchor_base_sizes = anchor_base_sizes)\n",
        "        \n",
        "    num_anchors = self.anchor_gen.num_anchors\n",
        "\n",
        "    self.ar_loc_heads = nn.ModuleList([\n",
        "        self._make_head_layer(plane_size[0], num_anchors * 4),\n",
        "        self._make_head_layer(plane_size[1], num_anchors * 4),\n",
        "        self._make_head_layer(plane_size[2], num_anchors * 4),\n",
        "        self._make_head_layer(plane_size[3], num_anchors * 4)\n",
        "    ])\n",
        "    \n",
        "    self.ar_cls_heads = nn.ModuleList([\n",
        "        self._make_head_layer(plane_size[0], num_anchors * 2),\n",
        "        self._make_head_layer(plane_size[1], num_anchors * 2),\n",
        "        self._make_head_layer(plane_size[2], num_anchors * 2),\n",
        "        self._make_head_layer(plane_size[3], num_anchors * 2)\n",
        "    ])\n",
        "    \n",
        "    self.od_loc_heads = nn.ModuleList([\n",
        "        self._make_head_layer(256, num_anchors * 4),\n",
        "        self._make_head_layer(256, num_anchors * 4),\n",
        "        self._make_head_layer(256, num_anchors * 4),\n",
        "        self._make_head_layer(256, num_anchors * 4)\n",
        "    ])\n",
        "    \n",
        "    self.od_cls_heads = nn.ModuleList([\n",
        "        self._make_head_layer(256, num_anchors * (num_classes+1)),\n",
        "        self._make_head_layer(256, num_anchors * (num_classes+1)),\n",
        "        self._make_head_layer(256, num_anchors * (num_classes+1)),\n",
        "        self._make_head_layer(256, num_anchors * (num_classes+1))\n",
        "    ])\n",
        "    \n",
        "    self.trans4 = nn.Sequential(nn.Conv2d(plane_size[3], 256, kernel_size=3, stride=1, padding=1),\n",
        "                                                     nn.ReLU(inplace=True),\n",
        "                                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1))\n",
        "    self.trans3 = nn.Sequential(nn.Conv2d(plane_size[2], 256, kernel_size=3, stride=1, padding=1),\n",
        "                                                     nn.ReLU(inplace=True),\n",
        "                                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1))\n",
        "    self.trans2 = nn.Sequential(nn.Conv2d(plane_size[1], 256, kernel_size=3, stride=1, padding=1),\n",
        "                                                     nn.ReLU(inplace=True),\n",
        "                                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1))\n",
        "    self.trans1 =  nn.Sequential(nn.Conv2d(plane_size[0], 256, kernel_size=3, stride=1, padding=1),\n",
        "                                                     nn.ReLU(inplace=True),\n",
        "                                                     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1))\n",
        "                                     \n",
        "    self.up4 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2, padding=0)\n",
        "    self.up3 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2, padding=0)\n",
        "    self.up2 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    self.latent4 = nn.Sequential(nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True))\n",
        "    self.latent3 = nn.Sequential(nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True))\n",
        "    self.latent2 = nn.Sequential(nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True))\n",
        "    self.latent1 = nn.Sequential(nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True))\n",
        "       \n",
        "    self._normal_init(self.layer5)\n",
        "    self._normal_init(self.ar_loc_heads)\n",
        "    self._normal_init(self.ar_cls_heads)\n",
        "    self._normal_init(self.od_loc_heads)\n",
        "    self._normal_init(self.od_cls_heads)\n",
        "    self._normal_init(self.trans4)\n",
        "    self._normal_init(self.trans3)\n",
        "    self._normal_init(self.trans2)\n",
        "    self._normal_init(self.trans1)\n",
        "    self._normal_init(self.up4)\n",
        "    self._normal_init(self.up3)\n",
        "    self._normal_init(self.up2)\n",
        "    self._normal_init(self.latent4)\n",
        "    self._normal_init(self.latent3)\n",
        "    self._normal_init(self.latent2)\n",
        "    self._normal_init(self.latent1)\n",
        "    \n",
        "\n",
        "  def _make_residual_layer(self, block, planes, blocks, stride=1):\n",
        "    downsample = None\n",
        "    if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "        downsample = nn.Sequential(\n",
        "            conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "            nn.BatchNorm2d(planes * block.expansion),\n",
        "        )\n",
        "\n",
        "    layers = []\n",
        "    layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "    self.inplanes = planes * block.expansion\n",
        "    for _ in range(1, blocks):\n",
        "        layers.append(block(self.inplanes, planes))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "  \n",
        "  def _make_head_layer(self, in_planes, out_planes, planes = 0, num_itr = 0):\n",
        "    head_layer = []\n",
        "    \n",
        "    if(num_itr > 0):\n",
        "      head_layer.append(nn.Conv2d(in_planes, planes, 3, 1, 1))\n",
        "      head_layer.append(nn.ReLU(True))\n",
        "      for i in range(1,num_itr):\n",
        "        if i == num_itr - 1:\n",
        "          head_layer.append(nn.Conv2d(planes, out_planes, 3, 1, 1))\n",
        "        else:\n",
        "          head_layer.append(nn.Conv2d(planes, planes, 3, 1, 1))\n",
        "          head_layer.append(nn.ReLU(True))\n",
        "    else:\n",
        "      head_layer.append(nn.Conv2d(in_planes, out_planes, 3, 1, 1))\n",
        "    \n",
        "    return nn.Sequential(*head_layer)\n",
        "  \n",
        "  def _normal_init(self, layer):\n",
        "    for m in layer.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "      if isinstance(m, nn.ConvTranspose2d):\n",
        "          nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          if m.bias is not None:\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "      if isinstance(m, Bottleneck):\n",
        "          nn.init.constant_(m.bn3.weight, 0)\n",
        "      elif isinstance(m, BasicBlock):\n",
        "          nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "              \n",
        "  def _upsample_add(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    return nn.functional.interpolate(x, size=(H,W), mode='bilinear') + y\n",
        "  \n",
        "  def _upsample_cat(self, x, y):\n",
        "    _,_,H,W = y.size()\n",
        "    layers = []\n",
        "    layers.append(y)\n",
        "    for sx in x:\n",
        "       layers.append(nn.functional.interpolate(sx, size=(H,W), mode='bilinear'))\n",
        "    return torch.cat(layers,1)\n",
        "    \n",
        "  def train(self, mode=True):\n",
        "    super(GCRefDet, self).train(mode)\n",
        "    #freeze bn\n",
        "    #if self.model == 'resnet18':\n",
        "    #  if mode:\n",
        "    #    for layer in self.modules():\n",
        "    #      if isinstance(layer, nn.BatchNorm2d):\n",
        "    #        layer.eval()\n",
        "            \n",
        "\n",
        "    \n",
        "  def forward(self,x):\n",
        "    c1 = self.layer1(x)\n",
        "    c2 = self.layer2(c1) #8\n",
        "    c3 = self.layer3(c2) #16\n",
        "    c4 = self.layer4(c3) #32\n",
        "    c5 = self.layer5(c4) #64\n",
        " \n",
        "    ar_locs = []\n",
        "    ar_clss = []\n",
        "    fm_size = []\n",
        "    for fm, ar_loc_head, ar_cls_head in zip([c2,c3,c4,c5], self.ar_loc_heads, self.ar_cls_heads):\n",
        "      ar_loc_h = ar_loc_head(fm)\n",
        "      ar_cls_h = ar_cls_head(fm)\n",
        "      ar_loc_h = ar_loc_h.permute(0, 2, 3, 1).contiguous().view(fm.size(0), -1, 4)\n",
        "      ar_cls_h = ar_cls_h.permute(0, 2, 3, 1).contiguous().view(fm.size(0), -1, 2)\n",
        "      ar_locs.append(ar_loc_h)\n",
        "      ar_clss.append(ar_cls_h)\n",
        "      fm_size.append(fm.size())\n",
        "    ar_locs = torch.cat(ar_locs,1)\n",
        "    ar_clss = torch.cat(ar_clss,1)\n",
        "    anchor = self.anchor_gen.get_anchor_boxes(fm_size)\n",
        "    \n",
        "    o4 = self.latent4(self.trans4(c5))\n",
        "    o3 = self.latent3(self.trans3(c4) + self.up4(o4))\n",
        "    o2 = self.latent2(self.trans2(c3) + self.up3(o3))\n",
        "    o1 = self.latent1(self.trans1(c2) + self.up2(o2))\n",
        "    \n",
        "    od_locs = []\n",
        "    od_clss = []\n",
        "    for fm, od_loc_head, od_cls_head in zip([o1,o2,o3,o4], self.od_loc_heads, self.od_cls_heads):\n",
        "      od_loc_h = od_loc_head(fm)\n",
        "      od_cls_h = od_cls_head(fm)\n",
        "      od_loc_h = od_loc_h.permute(0, 2, 3, 1).contiguous().view(fm.size(0), -1, 4)\n",
        "      od_cls_h = od_cls_h.permute(0, 2, 3, 1).contiguous().view(fm.size(0), -1, self.num_classes+1)\n",
        "      od_locs.append(od_loc_h)\n",
        "      od_clss.append(od_cls_h)\n",
        "    od_locs = torch.cat(od_locs,1)\n",
        "    od_clss = torch.cat(od_clss,1)\n",
        "    \n",
        "    return ar_locs, ar_clss, od_locs, od_clss, anchor\n",
        "  \n",
        "def testgc():\n",
        "  x = torch.randn((1,3, 576, 960))\n",
        "  model = GCRefDet(6,model='resnet34')\n",
        "  x = x.to(device)\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  ar_loc, ar_cls, od_loc, od_cls, anchor = model(x)\n",
        "  print(ar_loc[0].size())\n",
        "  print(ar_cls[0].size())\n",
        "  print(od_loc[0].size())\n",
        "  print(od_cls[0].size())\n",
        "  print(anchor.size())\n",
        "  print(anchor[0])\n",
        "  print(anchor[9])\n",
        "  print(anchor[18])\n",
        "  print(anchor[57*9])\n",
        "  print(anchor[57*9+9])\n",
        "  print(anchor[57*9-9])\n",
        "\n",
        "testgc()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.torch/models/resnet34-333f7ec4.pth\n",
            "100%|██████████| 87306240/87306240 [00:01<00:00, 49683284.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([103275, 4])\n",
            "torch.Size([103275, 2])\n",
            "torch.Size([103275, 4])\n",
            "torch.Size([103275, 7])\n",
            "torch.Size([103275, 4])\n",
            "tensor([-28., -28.,  35.,  35.])\n",
            "tensor([-20., -28.,  43.,  35.])\n",
            "tensor([-12., -28.,  51.,  35.])\n",
            "tensor([428., -28., 491.,  35.])\n",
            "tensor([436., -28., 499.,  35.])\n",
            "tensor([420., -28., 483.,  35.])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}