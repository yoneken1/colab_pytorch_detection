{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anchor.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Baj1TM97J8bz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Original:https://github.com/kuangliu/pytorch-retinanet/blob/master/encoder.py"
      ]
    },
    {
      "metadata": {
        "id": "11HTlmHXqT1q",
        "colab_type": "code",
        "outputId": "e053bba0-359e-4eaa-9553-76cdc8033bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "class Anchor:\n",
        "    def __init__(self, anchor_areas = [256*256.], \n",
        "                aspect_ratios = [1/1.,1/2., 2/1.],\n",
        "                scale_ratios = [1/2., 1., 2/1.],\n",
        "                anchor_base_sizes = [ 16. ] ):\n",
        "        self.anchor_areas = anchor_areas\n",
        "        self.aspect_ratios = aspect_ratios\n",
        "        self.scale_ratios = scale_ratios\n",
        "        self.anchor_base_sizes = anchor_base_sizes\n",
        "        self.anchor_wh = self._get_anchor_wh()\n",
        "        self.fm_sizes = None\n",
        "        self.anchors = None\n",
        "        self.num_anchors = len(self.aspect_ratios) * len(self.scale_ratios)\n",
        "\n",
        "    def _get_anchor_wh(self):\n",
        "        '''Compute anchor width and height for each feature map.\n",
        "        Returns:\n",
        "          anchor_wh: (tensor) anchor wh, sized [#fm, #anchors_per_cell, 2].\n",
        "        '''\n",
        "        anchor_wh = []\n",
        "        for s in self.anchor_areas:\n",
        "            for ar in self.aspect_ratios:  # w/h = ar\n",
        "                h = math.sqrt(s/ar)\n",
        "                w = ar * h\n",
        "                for sr in self.scale_ratios:  # scale\n",
        "                    anchor_h = h*sr\n",
        "                    anchor_w = w*sr\n",
        "                    anchor_wh.append([anchor_w, anchor_h])\n",
        "        return torch.Tensor(anchor_wh).view(len(self.anchor_areas), -1, 2)\n",
        "\n",
        "    def get_anchor_boxes(self, fm_sizes):\n",
        "        '''Compute anchor boxes for each feature map.\n",
        "        Args:\n",
        "          fm_size: (tensor) model feature map size.\n",
        "        Returns:\n",
        "          boxes: (list) anchor boxes for each feature map. Each of size [#anchors,4],\n",
        "                        where #anchors = fmw * fmh * #anchors_per_cell\n",
        "        '''\n",
        "        \n",
        "        if isinstance(fm_sizes,list):\n",
        "          fm_wh = []\n",
        "          for fm_size in fm_sizes:\n",
        "            fm_wh.append([fm_size[3],fm_size[2]]) # B,C,H,W\n",
        "          fm_sizes = torch.tensor(fm_wh)\n",
        "                   \n",
        "        if (self.fm_sizes is None) or (not torch.equal(fm_sizes,self.fm_sizes)):\n",
        "          self.fm_sizes = fm_sizes\n",
        "\n",
        "          boxes = []\n",
        "          \n",
        "          for i, fm_size in enumerate(self.fm_sizes):\n",
        "              anchor_base_size = self.anchor_base_sizes[i]\n",
        "              anchor_area = self.anchor_areas[i]\n",
        "              fm_w, fm_h = int(fm_size[0]), int(fm_size[1]) \n",
        "              h_grid, w_grid = torch.meshgrid(torch.arange(fm_h),torch.arange(fm_w))\n",
        "              xy = torch.cat([w_grid.unsqueeze(2),h_grid.unsqueeze(2)],2).float()\n",
        "              xy = xy\n",
        "              xy = (xy * (anchor_base_size) + (anchor_base_size - 1.)*0.5).view(fm_h,fm_w,1,2).expand(fm_h,fm_w, self.num_anchors,2)\n",
        "              wh = self.anchor_wh[i].view(1,1,self.num_anchors,2).expand(fm_h,fm_w,self.num_anchors,2)\n",
        "              box = torch.cat([xy - (wh - 1.) * 0.5, xy + (wh - 1.) * 0.5], 3)  # [x1,y1,x2,y2]\n",
        "              boxes.append(box.view(-1,4))\n",
        "          boxes = torch.cat(boxes, 0)\n",
        "          self.anchors = boxes\n",
        "        return self.anchors\n",
        "   \n",
        "def test():\n",
        "  anchor = Anchor()\n",
        "  fm = torch.randn(1,512,3,10).float()\n",
        "  fm_size = fm.size()\n",
        "  a = anchor.get_anchor_boxes([fm_size])\n",
        "  print(a[0])\n",
        "  print(a[9])\n",
        "  print(a[9*10])\n",
        "  print(a[9*10 - 9])\n",
        "  \n",
        "  fm = torch.randn(1,512,3,5).float()\n",
        "  fm_size = fm.size()\n",
        "  b = anchor.get_anchor_boxes([fm_size])\n",
        "  print(b[0])\n",
        "  print(b[9])\n",
        "  print(b[9*2])\n",
        "  print(b[9*3])\n",
        "\n",
        "\n",
        "test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-56., -56.,  71.,  71.])\n",
            "tensor([-40., -56.,  87.,  71.])\n",
            "tensor([-56., -40.,  71.,  87.])\n",
            "tensor([ 88., -56., 215.,  71.])\n",
            "tensor([-56., -56.,  71.,  71.])\n",
            "tensor([-40., -56.,  87.,  71.])\n",
            "tensor([-24., -56., 103.,  71.])\n",
            "tensor([ -8., -56., 119.,  71.])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}